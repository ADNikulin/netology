# Мониторинг и логи. Никулин Александр. 
# Домашнее задание к занятию 17 «Инцидент-менеджмент»

## Задание

Составьте постмортем на основе реального сбоя системы GitHub в 2018 году.

Информацию о сбое можно изучить по ссылкам ниже:

* [краткое описание на русском языке](https://habr.com/ru/post/427301/);
* [развёрнутое описание на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).
  
|      этап  | описание |
|------------------------------|-----------------------------------|
|  Краткое описание инцидента  |Проблема с соединением сети, в результате чего произошел сбой базы данных, что вызвало ошибки в отображении данных на веб-сайте github.com.|
|  Предшествующие события      |Плановые работы по техническому обслуживанию по замене неисправного оптического оборудования 100G|
|  Причина инцидента           |Потеря соединения между сетевым узлом на восточном побережье США и основным центром обработки данных на восточном побережье США|
|  Воздействие                 |Деградация части предоставления сервиса на 24 часа и 11 минут|
|  Обнаружение                 |Внутренние системы мониторинга начали регистрировать оповещения о многочисленных сбоях в работе системы 21 октября 2018 года в 22:54 по времени UTC.|
|  Реакция                     |В 23:02 UTC инженеры быстрой реакции обнаружили, что топологии множества кластеров баз данных находятся в нештатном состоянии. Обращение к API Orchestrator показало, что репликация базы данных включала только серверы из дата-центра на западном побережье США. В 23:09 UTC группа реагирования поменяла статус сайта на желтый. Это автоматически перевело ситуацию в активный инцидент и отправило предупреждение координатору. В 23:11 UTC координатор инцидентов присоединился и через две минуты изменил статус на красный.|
|Восстановление                |22 октября 2018 года в 00:05 UTC был разработан план по восстановлению системы. План включает в себя восстановление данных из резервных копий, синхронизацию реплик на обеих площадках, возвращение к стабильной топологии обслуживания и возобновление обработки заданий в очереди.|
|Таймлайн                      |сводка|
|2018-10-21 22:52 UTC          |Кратковременная потеря соединения между центрами обработки данных, начало деградации кластера БД|
|2018-10-21 22:54 UTC          |Генерация оповещений внутренней системы мониторинга|
|2018-10-21 23:02 UTC          |Подтверждение проблемы инженерами|
|2018-10-21 23:07 UTC          |Блокировка внутренних инструментов развертывания|
|2018-10-21 23:09 UTC          |Изменение статуса сервиса на желтый|
|2018-10-21 23:11 UTC          |Привлечение координатора инцидентов, изменение статуса сервиса на красный|
|2018-10-21 23:13 UTC          |Обнаружение конкретной проблемы с кластерами БД|
|2018-10-21 23:19 UTC          |Частичная контролируемая остановка выполнения заданий, выполняющих запись метаданных в БД|
|2018-10-22 00:05 UTC          |Разработка плана по восстановлению данных из резервных копий|
|2018-10-22 00:41 UTC          |Начало процесса восстановления данных из резервных копий|
|2018-10-22 06:51 UTC          |Начало второго этапа восстановления данных из резервных копий|
|2018-10-22 07:46 UTC          |Публикация сообщения с описанием сбоя в блоге|
|2018-10-22 11:12 UTC          |Завершение процесса восстановления данных. Начало процесса реплицирования данных между кластерами. Улучшение отзывчивости работы сайта|
|2018-10-22 13:15 UTC          |Предоставление дополнительных реплик чтения MySQL в общедоступном облаке Восточного побережья США для уменьшения задержи репликации на чтение.|
|2018-10-22 16:24 UTC          |Завершение синхронизации реплик. Статус сервисов сохранен на красном уровне, чтобы закончить процессы, накопившиеся за время сбоя.|
|2018-10-22 16:45 UTC          |Обработка фоновых задач, накопившихся за время аварии. Удаление устаревших задач.|
|2018-10-22 23:03 UTC          |Все ожидающие сборки веб-перехватчиков и страниц были завершены, и целостность всех систем была подтверждена. Статус сайта был изменен на "зеленый". Работа сервиса была восстановлена в штатном режиме.|
|Последующие действия          |Анализ бинарных журналов восстановления MySQL помог восстановить записи, которые не были скопированы в ЦОД Западного побережья. Настройки оркестровщика были изменены, чтобы предотвратить распространение основных баз данных за пределы региональных границ. Переход на новый механизм отчетов статуса сервиса был ускорен. За несколько недель до инцидента началась общекорпоративная инициатива по поддержке обслуживания трафика GitHub из нескольких ЦОД с поддержкой резервирования N+1. Внедрена практика проверки негативных сценариев до их возникновения.|
